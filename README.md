# ğŸ›ï¸ Ecommerce Analysis com Kedro
Este projeto Ã© uma pipeline robusta e modular para **anÃ¡lise e tratamento de dados de e-commerce**, com foco em marcas, comportamento do consumidor e inteligÃªncia de classificaÃ§Ã£o. Desenvolvido com [Kedro](https://kedro.org/) e tÃ©cnicas modernas de Machine Learning, ele processa grandes volumes de dados de forma eficiente e escalÃ¡vel.

## ğŸ’¡ Objetivo

Criar uma arquitetura de dados analÃ­tica, performÃ¡tica e inteligente que permita:
- Processar dados brutos de eventos do e-commerce
- Limpar, enriquecer e salvar dados em parquets organizados
- Gerar mÃ©tricas estatÃ­sticas para anÃ¡lise comportamental
- **Classificar automaticamente marcas por categoria** com zero-shot learning

---

## ğŸ” Funcionalidades

### ğŸ”¹ Fatiamento e OrganizaÃ§Ã£o de Dados
- Leitura eficiente de datasets massivos
- Salvamento em arquivos `.parquet` otimizados por lote

### ğŸ”¹ Limpeza e Enriquecimento
- PadronizaÃ§Ã£o e filtragem de eventos
- ExtraÃ§Ã£o de colunas Ãºteis como mÃªs, tipo de evento, preÃ§os

### ğŸ”¹ AnÃ¡lises EstatÃ­sticas
- GeraÃ§Ã£o de mÃ©tricas por cliente, marca, perÃ­odo e categoria
- ClusterizaÃ§Ã£o de clientes por poder de compra e comportamento

### ğŸ”¹ ClassificaÃ§Ã£o de Marcas (NLP Zero-Shot)
- Uso de modelos da Hugging Face (`facebook/bart-large-mnli`)
- InferÃªncia inteligente de categorias sem rÃ³tulos manuais
- Resultados salvos em `.parquet` prontos para uso analÃ­tico

---

## ğŸ“¦ Estrutura Kedro

```bash
fashion-analysis/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 01_raw/
â”‚   â”œâ”€â”€ 02_intermediate/
â”‚   â”œâ”€â”€ 03_primary/
â”‚   â””â”€â”€ 04_feature/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ fashion_analysis/
â”‚       â”œâ”€â”€ pipelines/
â”‚       â”‚   â”œâ”€â”€ fashion_etl/
â”‚       â”‚   â”œâ”€â”€ fashion_cleaning/
â”‚       â”‚   â”œâ”€â”€ cluster_clientes/
â”‚       â”‚   â””â”€â”€ classificar_marcas/
â”‚       â””â”€â”€ data_catalog.yml
â”œâ”€â”€ conf/
â”‚   â””â”€â”€ base/
â”‚       â”œâ”€â”€ catalog.yml
â”‚       â”œâ”€â”€ parameters.yml
â”‚       â””â”€â”€ logging.yml
â”œâ”€â”€ notebooks/
â””â”€â”€ README.md
```
## ğŸ¤– Tecnologias Utilizadas

- **Kedro**: estrutura profissional de pipelines com modularizaÃ§Ã£o, versionamento de dados e reprodutibilidade
- **Pandas** e **PyArrow**: para manipulaÃ§Ã£o e leitura eficiente de arquivos Parquet
- **NumPy**: usado para operaÃ§Ãµes vetoriais em anÃ¡lises e clusters
- **Scikit-learn**: para clustering de clientes com KMeans e mÃ©tricas de avaliaÃ§Ã£o
- **Hugging Face Transformers**: classificaÃ§Ã£o inteligente de marcas por categoria via zero-shot learning
- **tqdm**: acompanhamento de progresso em loops longos
- **Matplotlib**: geraÃ§Ã£o de grÃ¡ficos e visualizaÃ§Ãµes estatÃ­sticas
- **Jupyter Notebooks**: apoio nas anÃ¡lises exploratÃ³rias e validaÃ§Ã£o de hipÃ³teses
- **Python 3.12**: com ambiente virtual gerenciado por Conda

---

## ğŸ§  Estrutura das Pipelines

- `fashion_etl`: Fatiamento e organizaÃ§Ã£o de grandes arquivos em mÃºltiplos Parquets otimizados
- `fashion_cleaning`: Limpeza de dados com remoÃ§Ã£o de ruÃ­dos, tratamento de campos ausentes e transformaÃ§Ã£o de colunas
- `cluster_clientes`: Agrupamento de usuÃ¡rios com base em comportamento de compra, visualizaÃ§Ãµes e poder aquisitivo
- `classificar_marcas`: ClassificaÃ§Ã£o automÃ¡tica de marcas usando NLP (zero-shot) para definiÃ§Ã£o de categoria sem regras manuais

---

## ğŸ“Š MÃ©tricas e AnÃ¡lises

- Clientes Ãºnicos, tÃ­quete mÃ©dio, churn, tempo mÃ©dio de carrinho, conversÃ£o por cluster
- EstatÃ­sticas descritivas para apoiar decisÃµes de negÃ³cios
- AnÃ¡lise temporal dos eventos por tipo e valor de compra
- Agrupamento de sellers com base em comportamento para prospecÃ§Ã£o inteligente

---

## ğŸ“Š Dashboards AnalÃ­ticos

- VisualizaÃ§Ã£o interativa via **Streamlit** com insights por cluster, marca e comportamento
- AnÃ¡lises de **LTV**, conversÃ£o, churn, tempo mÃ©dio no carrinho e horÃ¡rio mais comum de compra
- Ranking de marcas por aÃ§Ã£o do usuÃ¡rio (*view*, *cart*, *purchase*)
- PrevisÃµes de compras mensais com **Prophet** e regressÃ£o por cliente + marca
- VisualizaÃ§Ã£o dos dados prÃ© e pÃ³s-modelagem para apoio estratÃ©gico

---

## ğŸ“ˆ Potenciais AplicaÃ§Ãµes

- SegmentaÃ§Ã£o de usuÃ¡rios e sellers para campanhas e recomendaÃ§Ãµes
- InteligÃªncia comercial por tipo de marca
- Apoio a dashboards de vendas e acompanhamento estratÃ©gico
- PriorizaÃ§Ã£o de leads de sellers com base em cluster de comportamento

---

## ğŸ’Œ ContribuiÃ§Ã£o

Este projeto Ã© uma iniciativa independente e experimental de anÃ¡lise de dados com foco em e-commerce.  
Sinta-se Ã  vontade para contribuir com melhorias, ideias ou feedbacks!

---

ğŸš€ Feito com ğŸ’– por uma mente analÃ­tica e criativa que transforma dados em inteligÃªncia.

---

## ğŸ‘©â€ğŸ’» Author

Developed with ğŸ’™ by **Marcela Nako**  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/marcelaabe-alvim/)  
ğŸ’¼ [GitHub](https://github.com/maabenako?tab=repositories)

---

# Ennglish:

---
# ğŸ›ï¸ Ecommerce Analysis with Kedro

This project is a robust and modular pipeline for **e-commerce data analysis and processing**, focusing on brands, consumer behavior, and intelligent classification. Built with [Kedro](https://kedro.org/) and modern Machine Learning techniques, it efficiently processes large volumes of data in a scalable architecture.

## ğŸ’¡ Objective

To build an intelligent and high-performance data architecture that enables:
- Processing raw e-commerce event data  
- Cleaning, enriching, and saving structured Parquet files  
- Generating statistical metrics for behavioral analysis  
- **Automatically classifying brands by category** using zero-shot learning

---

## ğŸ” Features

### ğŸ”¹ Data Slicing & Organization
- Efficient loading of massive datasets  
- Saving optimized `.parquet` files in batches

### ğŸ”¹ Cleaning & Enrichment
- Standardization and filtering of events  
- Extraction of useful columns such as month, event type, and prices

### ğŸ”¹ Statistical Analysis
- Metrics by customer, brand, period, and category  
- Clustering of clients by purchasing power and behavior

### ğŸ”¹ Brand Classification (Zero-Shot NLP)
- Leverages Hugging Face models (`facebook/bart-large-mnli`)  
- Intelligent category inference without manual labeling  
- Results saved in `.parquet` format for analytical use

---

## ğŸ“¦ Kedro Structure

```bash
fashion-analysis/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 01_raw/
â”‚   â”œâ”€â”€ 02_intermediate/
â”‚   â”œâ”€â”€ 03_primary/
â”‚   â””â”€â”€ 04_feature/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ fashion_analysis/
â”‚       â”œâ”€â”€ pipelines/
â”‚       â”‚   â”œâ”€â”€ fashion_etl/
â”‚       â”‚   â”œâ”€â”€ fashion_cleaning/
â”‚       â”‚   â”œâ”€â”€ cluster_clientes/
â”‚       â”‚   â””â”€â”€ classificar_marcas/
â”‚       â””â”€â”€ data_catalog.yml
â”œâ”€â”€ conf/
â”‚   â””â”€â”€ base/
â”‚       â”œâ”€â”€ catalog.yml
â”‚       â”œâ”€â”€ parameters.yml
â”‚       â””â”€â”€ logging.yml
â”œâ”€â”€ notebooks/
â””â”€â”€ README.md
```

---

## ğŸ¤– Technologies Used

- **Kedro**: Professional pipeline framework with modularity, data versioning, and reproducibility  
- **Pandas** & **PyArrow**: For fast and efficient manipulation of Parquet files  
- **NumPy**: Used for vector operations in analysis and clustering  
- **Scikit-learn**: Customer clustering with KMeans and evaluation metrics  
- **Hugging Face Transformers**: Intelligent brand classification via zero-shot learning  
- **tqdm**: Progress tracking for long loops  
- **Matplotlib**: Visualization of statistical charts  
- **Jupyter Notebooks**: Support for exploratory analysis and hypothesis testing  
- **Python 3.12**: Environment managed with Conda

---

## ğŸ§  Pipeline Structure

- `fashion_etl`: Slicing and organizing large files into multiple optimized Parquet files  
- `fashion_cleaning`: Data cleaning with noise removal, missing value treatment, and column transformation  
- `cluster_clientes`: User grouping based on purchasing behavior, views, and income potential  
- `classificar_marcas`: Automated brand classification using NLP (zero-shot) for category assignment without rules

---

## ğŸ“Š Metrics & Analysis

- Unique customers, average ticket size, churn, average cart time, conversion by cluster  
- Descriptive statistics to support business decisions  
- Temporal analysis of events by type and value  
- Clustering of sellers for intelligent prospecting

---

## ğŸ“Š Analytical Dashboards

- Interactive **Streamlit** dashboard showing insights by cluster, brand, and behavior
- Analysis of **LTV**, conversion, churn, average cart time, and most common purchase time
- Brand ranking by user interaction (*view*, *cart*, *purchase*)
- Monthly purchase forecasting using **Prophet** and user+brand-level regressions
- Data visualization before and after modeling for strategic decision support

---

## ğŸ“ˆ Potential Applications

- User and seller segmentation for campaigns and recommendations  
- Commercial intelligence by brand type  
- Support for sales dashboards and strategic monitoring  
- Prioritization of seller leads based on behavior clusters

---

## ğŸ’Œ Contribution

This is an independent and experimental data analysis project focused on e-commerce.  
Feel free to contribute with improvements, ideas, or feedback!

---

ğŸš€ Made with ğŸ’– by an analytical and creative mind turning data into intelligence.

---

## ğŸ‘©â€ğŸ’» Author

Developed with ğŸ’™ by **Marcela Nako**  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/marcelaabe-alvim/)  
ğŸ’¼ [GitHub](https://github.com/maabenako?tab=repositories)
