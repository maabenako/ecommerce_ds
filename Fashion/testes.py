import pandas as pd
from pathlib import Path

# Caminho atÃ© o CSV (ajuste se necessÃ¡rio)
caminho_csv = Path(__file__).resolve().parent / "2019-Oct.csv"

# LÃª as 1000 primeiras linhas
df = pd.read_csv(caminho_csv, nrows=1000)

# Mostra as 10 primeiras linhas
print("ğŸ“Œ Primeiras linhas:")
print(df.head(10), "\n")

# Mostra colunas e tipos
print("ğŸ§  Tipos de dados:")
print(df.dtypes, "\n")

# Verifica valores faltantes
print("â— Valores faltando por coluna:")
print(df.isnull().sum(), "\n")

print("ğŸ“Š Percentual de valores faltando:")
print((df.isnull().mean() * 100).round(2), "\n")

# SugestÃµes automÃ¡ticas de tratamento
print("ğŸ’¡ SugestÃµes de tratamento:")

for coluna in df.columns:
    faltantes = df[coluna].isnull().mean()
    tipo = df[coluna].dtype

    if faltantes > 0:
        if tipo == "object":
            print(f"ğŸ”¹ '{coluna}': preencher com 'unknown'")
        elif "float" in str(tipo) or "int" in str(tipo):
            print(f"ğŸ”¹ '{coluna}': preencher com mÃ©dia ou mediana")
    else:
        print(f"âœ… '{coluna}': sem valores faltantes")

print(df.info())
print(df)
print(df["event_type"].unique())



###

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# LÃª os dados clusterizados
df = pd.read_parquet("/home/maabe/fashion-analysis/data/07_model_output/clientes_clusterizados.parquet")

# Mostra os primeiros registros
print("ğŸ“‹ PrÃ©via dos dados:")
print(df.head())

# DistribuiÃ§Ã£o por cluster
print("\nğŸ‘¥ Quantidade de clientes por cluster:")
print(df["cluster"].value_counts())

# EstatÃ­sticas por cluster
print("\nğŸ“Š MÃ©dias por cluster:")
print(df.groupby("cluster").mean(numeric_only=True))

# VisualizaÃ§Ã£o
sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.scatterplot(
    data=df.sample(10000),  # reduz visualizaÃ§Ã£o pra nÃ£o travar
    x="total_gasto",
    y="media_gasto",
    hue="cluster",
    palette="tab10"
)
plt.title("ClusterizaÃ§Ã£o de Clientes por Poder de Compra")
plt.xlabel("Total Gasto")
plt.ylabel("Gasto MÃ©dio")
plt.tight_layout()
plt.show()

# Ver os centroides dos clusters
print("\nğŸ“ Centroides dos clusters (total_gasto x media_gasto):")

centroides = df.groupby("cluster")[["total_gasto", "media_gasto"]].mean().reset_index()
print(centroides)

centroides.to_csv("centroides_clusters.csv", index=False)
print("ğŸ“ Arquivo 'centroides_clusters.csv' salvo com sucesso!")


import pandas as pd
import os

# Caminho da pasta com os Parquets
pasta = "/home/maabe/fashion-analysis/data/02_intermediate/cleaned_parquets"

# Lista os arquivos
arquivos = sorted([f for f in os.listdir(pasta) if f.endswith(".parquet")])

# Carrega sÃ³ o primeiro pedaÃ§o para inspecionar
df = pd.read_parquet(os.path.join(pasta, arquivos[0]))

# Mostra as colunas e os primeiros registros
print("Colunas:", df.columns.tolist())
print("\nTipos de dados:")
print(df.dtypes)

print("\nAmostra de dados:")
print(df.head())

###

# Parquet de classificaÃ§Ã£o de marcas com NLP

import pandas as pd

# Caminho do arquivo
caminho = "/home/maabe/fashion-analysis/data/08_reporting/marcas_classificadas.parquet"

# LÃª o Parquet
df = pd.read_parquet(caminho)

# Mostra info geral e uma amostra
print("ğŸ“Š InformaÃ§Ãµes do DataFrame:")
print(df.info())

print("\nğŸ” Primeiras 10 linhas:")
print(df.sample(10, random_state=42))  # amostra aleatÃ³ria
